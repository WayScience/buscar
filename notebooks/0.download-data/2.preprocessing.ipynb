{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e412a0f9",
   "metadata": {},
   "source": [
    "# 2. Preprocessing Data\n",
    "\n",
    "In this notebook, we explore the contents of the downloaded dataset and perform preprocessing steps to prepare the data for downstream analysis.\n",
    "**Overview**\n",
    "\n",
    "We focus on concatenating profiles from plates containing CRISPR knockdown experiments. The workflow includes:\n",
    "\n",
    "1. **Plate Selection**: Loading only plates with CRISPR knockdown wells from the experimental metadata\n",
    "2. **Feature Space Reduction**: Using the shared feature space defined in the [JUMP-single-cell repository](https://github.com/WayScience/JUMP-single-cell)\n",
    "3. **Data Concatenation**: Combining all selected plates into a single DataFrame with consistent features\n",
    "4. **Metadata Preservation**: Generating a JSON record containing metadata and shared feature information for reproducibility\n",
    "\n",
    "This preprocessing ensures all profiles share the same feature space and are ready for comparative analysis across different experimental conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0387feba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pathlib\n",
    "from typing import Optional\n",
    "\n",
    "import polars as pl\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from utils.utils import split_meta_and_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33f13a",
   "metadata": {},
   "source": [
    "## Helper functions \n",
    "\n",
    "Contains helper function that pertains to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2902dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_concat_profiles(\n",
    "    profile_dir: str | pathlib.Path,\n",
    "    shared_features: Optional[list[str]] = None,\n",
    "    specific_plates: Optional[list[pathlib.Path]] = None,\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Load all profile files from a directory and concatenate them into a single Polars DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    profile_dir : str or pathlib.Path\n",
    "        Directory containing the profile files (.parquet).\n",
    "    shared_features : Optional[list[str]], optional\n",
    "        List of shared feature names to filter the profiles. If None, all features are loaded.\n",
    "    specific_plates : Optional[list[pathlib.Path]], optional\n",
    "        List of specific plate file paths to load. If None, all profiles in the directory are loaded.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        Concatenated Polars DataFrame containing all loaded profiles.\n",
    "    \"\"\"\n",
    "    # Ensure profile_dir is a pathlib.Path\n",
    "    if isinstance(profile_dir, str):\n",
    "        profile_dir = pathlib.Path(profile_dir)\n",
    "    elif not isinstance(profile_dir, pathlib.Path):\n",
    "        raise TypeError(\"profile_dir must be a string or a pathlib.Path object\")\n",
    "\n",
    "    # Validate specific_plates\n",
    "    if specific_plates is not None:\n",
    "        if not isinstance(specific_plates, list):\n",
    "            raise TypeError(\"specific_plates must be a list of pathlib.Path objects\")\n",
    "        if not all(isinstance(path, pathlib.Path) for path in specific_plates):\n",
    "            raise TypeError(\n",
    "                \"All elements in specific_plates must be pathlib.Path objects\"\n",
    "            )\n",
    "\n",
    "    def load_profile(file: pathlib.Path) -> pl.DataFrame:\n",
    "        \"\"\"internal function to load a single profile file.\n",
    "        \"\"\"\n",
    "        profile_df = pl.read_parquet(file)\n",
    "        meta_cols, _ = split_meta_and_features(profile_df)\n",
    "        if shared_features is not None:\n",
    "            # Only select metadata and shared features\n",
    "            return profile_df.select(meta_cols + shared_features)\n",
    "        return profile_df\n",
    "\n",
    "    # Use specific_plates if provided, otherwise gather all .parquet files\n",
    "    if specific_plates is not None:\n",
    "        # Validate that all specific plate files exist\n",
    "        for plate_path in specific_plates:\n",
    "            if not plate_path.exists():\n",
    "                raise FileNotFoundError(f\"Profile file not found: {plate_path}\")\n",
    "        files_to_load = specific_plates\n",
    "    else:\n",
    "        files_to_load = list(profile_dir.glob(\"*.parquet\"))\n",
    "        if not files_to_load:\n",
    "            raise FileNotFoundError(f\"No profile files found in {profile_dir}\")\n",
    "\n",
    "    # Load and concatenate profiles\n",
    "    loaded_profiles = [load_profile(f) for f in files_to_load]\n",
    "\n",
    "    # Concatenate all loaded profiles\n",
    "    return pl.concat(loaded_profiles, rechunk=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f8d2d9",
   "metadata": {},
   "source": [
    "Defining the input and output directories used throughout the notebook.\n",
    "\n",
    "> **Note:** The shared profiles utilized here are sourced from the [JUMP-single-cell](https://github.com/WayScience/JUMP-single-cell) repository. All preprocessing and profile generation steps are performed in that repository, and this notebook focuses on downstream analysis using the generated profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea207e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting data directory\n",
    "data_dir = pathlib.Path(\"./data\").resolve(strict=True)\n",
    "\n",
    "# Setting profiles directory\n",
    "profiles_dir = (data_dir / \"sc-profiles\").resolve(strict=True)\n",
    "\n",
    "# Experimental metadata\n",
    "exp_metadata_path = (data_dir / \"CPJUMP1-experimental-metadata.csv\").resolve(strict=True)\n",
    "\n",
    "# Setting feature selection path\n",
    "shared_features_config_path = (data_dir / \"feature_selected_sc_qc_features.json\").resolve(strict=True)\n",
    "\n",
    "# Make a results folder\n",
    "results_dir = pathlib.Path(\"./results\").resolve()\n",
    "results_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168a71a",
   "metadata": {},
   "source": [
    "Create a list of paths that only points crispr treated plates and load the shared features config file that can be found in this [repo](https://github.com/WayScience/JUMP-single-cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7944fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experimental metadata\n",
    "exp_metadata = pl.read_csv(exp_metadata_path)\n",
    "crispr_plate_names = exp_metadata.select(\"Assay_Plate_Barcode\").unique().to_series().to_list()\n",
    "crispr_plate_paths = [\n",
    "        (profiles_dir / f\"{plate}_feature_selected_sc_qc.parquet\").resolve(strict=True) for plate in crispr_plate_names\n",
    "    ]\n",
    "# Load shared features\n",
    "with open(shared_features_config_path) as f:\n",
    "    loaded_shared_features = json.load(f)\n",
    "\n",
    "shared_features = loaded_shared_features[\"shared-features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bfd5c7",
   "metadata": {},
   "source": [
    "Using the filtered CRISPR plate file paths and shared features configuration, we load all individual profile files and concatenate them into a single comprehensive DataFrame. This step combines data from multiple experimental plates while maintaining the consistent feature space defined by the shared features list.\n",
    "\n",
    "The concatenation process ensures:\n",
    "- All profiles use the same feature set for downstream compatibility\n",
    "- Metadata columns are preserved across all plates\n",
    "- Data integrity is maintained during the merge operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6f7e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading crispr profiles with shared features and concat into a single DataFrame\n",
    "loaded_profiles = load_and_concat_profiles(\n",
    "    profile_dir=profiles_dir,\n",
    "    specific_plates=crispr_plate_paths,\n",
    "    shared_features=shared_features\n",
    ")\n",
    "\n",
    "# Add index column \n",
    "loaded_profiles = loaded_profiles.with_row_index(\"index\")\n",
    "\n",
    "# Split meta and features\n",
    "meta_cols, features_cols = split_meta_and_features(loaded_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76918a03",
   "metadata": {},
   "source": [
    "Saving the concatenated CRISPR profiles and feature space information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2acadc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving metadata and features of the concat profile into a json file\n",
    "meta_features_dict = {\n",
    "    \"concat-profiles\": {\n",
    "        \"meta-features\": meta_cols,\n",
    "        \"shared-features\": features_cols\n",
    "    }\n",
    "}\n",
    "with open(results_dir / \"concat_profiles_meta_features.json\", \"w\") as f:\n",
    "    json.dump(meta_features_dict, f, indent=4)\n",
    "\n",
    "# Save the concated profiles\n",
    "loaded_profiles.write_parquet(\n",
    "    results_dir / \"concat_crispr_profiles.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "buscar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
